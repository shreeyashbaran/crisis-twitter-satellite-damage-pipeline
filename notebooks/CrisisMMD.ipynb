{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93eb112c-283e-4e13-a0c6-6df3bc978b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1: imports, config, seeds ===\n",
    "from pathlib import Path\n",
    "import os, re, json, math, random, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Artifacts dir\n",
    "ARTIFACTS = Path(\"./artifacts_stage1\")\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37af160a-d8b4-4f31-bc03-4d393bb71e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT exists: True\n",
      "SPLIT_DIR exists: True\n",
      "IMG_ROOT exists: True\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: paths and helpers ===\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "# Repo-friendly path handling:\n",
    "# - default expects datasets under the repo root: ./CrisisMMD_v2.0 and ./BRIGHT\n",
    "# - you can override with environment variables:\n",
    "#     CRISISMMD_ROOT=/path/to/CrisisMMD_v2.0\n",
    "#     BRIGHT_ROOT=/path/to/BRIGHT\n",
    "#\n",
    "# Tip (Windows PowerShell):\n",
    "#   setx CRISISMMD_ROOT \"C:\\\\path\\\\to\\\\CrisisMMD_v2.0\"\n",
    "\n",
    "# Import shared config (repo_root + env var support)\n",
    "sys.path.append(str(Path.cwd().resolve().parent if Path.cwd().name.lower()==\"notebooks\" else Path.cwd().resolve()))\n",
    "from src.config import CRISISMMD_ROOT as DATA_ROOT\n",
    "\n",
    "SPLIT_DIR = DATA_ROOT / \"crisismmd_datasplit_all\" / \"crisismmd_datasplit_all\"\n",
    "IMG_ROOT  = DATA_ROOT / \"data_image\"\n",
    "\n",
    "print(\"DATA_ROOT:\", DATA_ROOT, \"| exists:\", DATA_ROOT.exists())\n",
    "print(\"SPLIT_DIR:\", SPLIT_DIR, \"| exists:\", SPLIT_DIR.exists())\n",
    "print(\"IMG_ROOT :\", IMG_ROOT,  \"| exists:\", IMG_ROOT.exists())\n",
    "\n",
    "def resolve_image_path(relpath: str) -> Path | None:\n",
    "    \"\"\"Resolve an 'image' field to an absolute path under DATA_ROOT/data_image.\"\"\"\n",
    "    if not isinstance(relpath, str) or relpath.strip() == \"\":\n",
    "        return None\n",
    "    p = Path(relpath)\n",
    "    if p.is_absolute():\n",
    "        return p\n",
    "    s = relpath.replace(\"\\\\\", \"/\").lstrip(\"./\")\n",
    "    if s.lower().startswith(\"data_image/\"):\n",
    "        return (DATA_ROOT / s).resolve()\n",
    "    return (IMG_ROOT / s).resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d047ad1c-7b78-436b-8dc5-ccb8bd167592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: robust TSV reader (handles quotes/encodings) ===\n",
    "import csv\n",
    "\n",
    "def read_tsv_robust(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Tolerant TSV reader for CrisisMMD splits.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=\"\\t\", engine=\"python\",\n",
    "                           quoting=csv.QUOTE_NONE, escapechar=\"\\\\\",\n",
    "                           on_bad_lines=\"skip\", encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, sep=\"\\t\", engine=\"python\",\n",
    "                           on_bad_lines=\"skip\", encoding=\"latin-1\")\n",
    "\n",
    "def load_task(prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"Load train/dev/test for a task prefix: task_informative|task_humanitarian|task_damage.\"\"\"\n",
    "    frames = []\n",
    "    for split in (\"train\", \"dev\", \"test\"):\n",
    "        p = SPLIT_DIR / f\"{prefix}_text_img_{split}.tsv\"\n",
    "        if not p.exists():\n",
    "            print(\"Missing:\", p)\n",
    "            continue\n",
    "        df = read_tsv_robust(p)\n",
    "        df[\"__split\"] = split\n",
    "        df[\"__source\"] = str(p)\n",
    "        frames.append(df)\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.concat(frames, ignore_index=True, sort=False)\n",
    "    # standardize column names we care about\n",
    "    rename = {}\n",
    "    for c in df.columns:\n",
    "        cl = c.strip().lower()\n",
    "        if cl == \"event_name\": rename[c] = \"event_name\"\n",
    "        if cl == \"tweet_id\":   rename[c] = \"tweet_id\"\n",
    "        if cl == \"image_id\":   rename[c] = \"image_id\"\n",
    "        if cl == \"tweet_text\": rename[c] = \"tweet_text\"\n",
    "        if cl == \"image\":      rename[c] = \"image\"\n",
    "        if cl == \"label\":      rename[c] = \"label\"\n",
    "        if cl == \"label_text\": rename[c] = \"label_text\"\n",
    "        if cl == \"label_image\":rename[c] = \"label_image\"\n",
    "        if cl == \"label_text_image\": rename[c] = \"label_text_image\"\n",
    "    return df.rename(columns=rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b08eb1-7e06-483e-b584-a8dda98c6b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows â€” info: 18082 | hum: 18082 | dmg: 3526\n",
      "Info columns: ['event_name', 'tweet_id', 'image_id', 'tweet_text', 'image', 'label', 'label_text', 'label_image', 'label_text_image', '__split', '__source']\n",
      "Hum columns: ['event_name', 'tweet_id', 'image_id', 'tweet_text', 'image', 'label', 'label_text', 'label_image', 'label_text_image', '__split', '__source']\n",
      "Dmg columns: ['event_name', 'tweet_id', 'image_id', 'tweet_text', 'image', 'label', '__split', '__source']\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: load splits ===\n",
    "df_info = load_task(\"task_informative\")\n",
    "df_hum  = load_task(\"task_humanitarian\")\n",
    "df_dmg  = load_task(\"task_damage\")\n",
    "\n",
    "print(\"Rows â€” info:\", len(df_info), \"| hum:\", len(df_hum), \"| dmg:\", len(df_dmg))\n",
    "print(\"Info columns:\", list(df_info.columns))\n",
    "print(\"Hum columns:\", list(df_hum.columns))\n",
    "print(\"Dmg columns:\", list(df_dmg.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e3acd3-3f95-4b07-a556-f4e401418dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: text cleaner and label normalizers (v2.0) ===\n",
    "\n",
    "def norm_text(s):\n",
    "    if not isinstance(s, str): return s\n",
    "    s = s.replace(\"\\r\",\" \").replace(\"\\n\",\" \").strip()\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" <URL> \", s)\n",
    "    s = re.sub(r\"@\\w+\", \" <USER> \", s)\n",
    "    s = re.sub(r\"#(\\w+)\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Maps per README\n",
    "HUM_MAP = {\n",
    "    \"affected individuals\": \"affected_individuals\",\n",
    "    \"infrastructure and utility damage\": \"infrastructure_and_utility_damage\",\n",
    "    \"injured or dead people\": \"injured_or_dead_people\",\n",
    "    \"missing or found people\": \"missing_or_found_people\",\n",
    "    \"rescue, volunteering or donation effort\": \"rescue_volunteering_or_donation_effort\",\n",
    "    \"vehicle damage\": \"vehicle_damage\",\n",
    "    \"other relevant information\": \"other_relevant_information\",\n",
    "    \"not humanitarian\": \"not_humanitarian\",\n",
    "    \"not relevant or can't judge\": \"not_humanitarian\",  # v2.0 change\n",
    "}\n",
    "\n",
    "DMG_MAP = {\n",
    "    # severe\n",
    "    \"severe_damage\": \"severe\", \"severe damage\": \"severe\", \"severe\": \"severe\",\n",
    "    # mild-ish collapsed\n",
    "    \"mild_damage\": \"mild\", \"mild damage\": \"mild\", \"mild\": \"mild\",\n",
    "    \"moderate_damage\": \"mild\", \"moderate damage\": \"mild\",\n",
    "    \"minor_damage\": \"mild\", \"minor damage\": \"mild\",\n",
    "    # little/none\n",
    "    \"little_or_no_damage\": \"little_or_none\", \"little or no damage\": \"little_or_none\",\n",
    "    \"little-to-no damage\": \"little_or_none\", \"little-to-no\": \"little_or_none\",\n",
    "    \"little/no\": \"little_or_none\", \"no_damage\": \"little_or_none\",\n",
    "    \"no damage\": \"little_or_none\", \"none\": \"little_or_none\", \"low_damage\": \"little_or_none\",\n",
    "}\n",
    "\n",
    "def n_info(x):\n",
    "    if pd.isna(x): return None\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"informative\",\"info\",\"yes\",\"1\",\"true\"}: return \"informative\"\n",
    "    if s in {\"not informative\",\"not_informative\",\"not-informative\",\"no\",\"0\",\"false\"}: return \"not_informative\"\n",
    "    return s\n",
    "\n",
    "def n_hum(x):\n",
    "    if pd.isna(x): return None\n",
    "    s = str(x).strip().lower()\n",
    "    if s in HUM_MAP: return HUM_MAP[s]\n",
    "    for k,v in HUM_MAP.items():\n",
    "        if k in s: return v\n",
    "    if \"not\" in s and \"humanitarian\" in s: return \"not_humanitarian\"\n",
    "    return s.replace(\" \", \"_\")\n",
    "\n",
    "def n_dmg(x):\n",
    "    if pd.isna(x): return None\n",
    "    s = str(x).strip().lower().replace(\"-\", \"_\")\n",
    "    return DMG_MAP.get(s, DMG_MAP.get(s.replace(\"_\", \" \"), None))\n",
    "\n",
    "# Clean text\n",
    "for d in (df_info, df_hum, df_dmg):\n",
    "    if \"tweet_text\" in d:\n",
    "        d[\"text_clean\"] = d[\"tweet_text\"].map(norm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1f11dd-d820-48dc-bb1f-d1577517f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 counts: {'informative': 12862, 'not_informative': 5220}\n",
      "Task2 counts: {'other_relevant_information': 6505, 'not_humanitarian': 5220, 'rescue_volunteering_or_donation_effort': 3774, 'infrastructure_and_utility_damage': 1430, 'injured_or_dead_people': 533, 'affected_individuals': 518, 'vehicle_damage': 61, 'missing_or_found_people': 41}\n",
      "Task3 counts: {'severe': 2212, 'mild': 839, 'little_or_none': 475}\n"
     ]
    }
   ],
   "source": [
    "# === Cell 6: canonical datasets + v2.0 alignment (Task1â†”Task2) ===\n",
    "\n",
    "# Task 1 (informative)\n",
    "info = df_info.copy()\n",
    "for col in (\"label\",\"label_text\",\"label_image\"):\n",
    "    if col in info: info[col] = info[col].map(n_info)\n",
    "info[\"informativeness_label\"] = info.get(\"label_text\").fillna(info.get(\"label_image\")).fillna(info.get(\"label\"))\n",
    "info = info[[\"event_name\",\"tweet_id\",\"image_id\",\"text_clean\",\"image\",\"informativeness_label\",\"__split\"]]\n",
    "\n",
    "# Task 2 (humanitarian)\n",
    "hum = df_hum.copy()\n",
    "for col in (\"label\",\"label_text\",\"label_image\"):\n",
    "    if col in hum: hum[col] = hum[col].map(n_hum)\n",
    "hum[\"humanitarian_label\"] = hum.get(\"label_text\").fillna(hum.get(\"label_image\")).fillna(hum.get(\"label\"))\n",
    "hum = hum[[\"event_name\",\"tweet_id\",\"image_id\",\"text_clean\",\"image\",\"humanitarian_label\",\"__split\"]]\n",
    "\n",
    "# Merge to enforce v2.0 alignment: not_informative <-> not_humanitarian\n",
    "merged = pd.merge(info, hum, on=[\"tweet_id\",\"image_id\"], how=\"outer\", suffixes=(\"_info\",\"_hum\"))\n",
    "mask_not_info = merged[\"informativeness_label\"].eq(\"not_informative\")\n",
    "merged.loc[mask_not_info, \"humanitarian_label\"] = \"not_humanitarian\"\n",
    "mask_not_hum = merged[\"humanitarian_label\"].eq(\"not_humanitarian\")\n",
    "merged.loc[mask_not_hum, \"informativeness_label\"] = \"not_informative\"\n",
    "merged[\"split\"] = merged[\"__split_info\"].fillna(merged[\"__split_hum\"])\n",
    "\n",
    "# Task 3 (damage)\n",
    "dmg = df_dmg.copy()\n",
    "raw_col = \"label_image\" if \"label_image\" in dmg.columns and dmg[\"label_image\"].notna().any() else \"label\"\n",
    "dmg[\"damage_severity_label\"] = dmg[raw_col].map(n_dmg)\n",
    "valid = {\"little_or_none\",\"mild\",\"severe\"}\n",
    "dmg = dmg[dmg[\"damage_severity_label\"].isin(valid)].copy()\n",
    "dmg = dmg[[\"event_name\",\"tweet_id\",\"image_id\",\"text_clean\",\"image\",\"damage_severity_label\",\"__split\"]]\n",
    "dmg.rename(columns={\"__split\":\"split\"}, inplace=True)\n",
    "\n",
    "print(\"Task1 counts:\", info[\"informativeness_label\"].value_counts(dropna=False).to_dict())\n",
    "print(\"Task2 counts:\", hum[\"humanitarian_label\"].value_counts(dropna=False).to_dict())\n",
    "print(\"Task3 counts:\", dmg[\"damage_severity_label\"].value_counts(dropna=False).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7815c3a1-cffe-4379-9383-763610c16910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task1: rows=18082\n",
      "Splits: {'train': 13608, 'dev': 2237, 'test': 2237}\n",
      "Label counts: {'informative': 12862, 'not_informative': 5220}\n",
      "\n",
      "Task2: rows=18082\n",
      "Splits: {'train': 13608, 'dev': 2237, 'test': 2237}\n",
      "Label counts: {'other_relevant_information': 6505, 'not_humanitarian': 5220, 'rescue_volunteering_or_donation_effort': 3774, 'infrastructure_and_utility_damage': 1430, 'injured_or_dead_people': 533, 'affected_individuals': 518, 'vehicle_damage': 61, 'missing_or_found_people': 41}\n",
      "\n",
      "Task3: rows=3526\n",
      "Splits: {'train': 2468, 'dev': 529, 'test': 529}\n",
      "Label counts: {'severe': 2212, 'mild': 839, 'little_or_none': 475}\n",
      "\n",
      "Alignment violations â€” not_info->not_hum: 0 | not_hum->not_info: 0\n",
      "\n",
      "Images â€” info:\n",
      "Images existing: 18082/18082\n",
      "Images â€” hum:\n",
      "Images existing: 18082/18082\n",
      "Images â€” dmg:\n",
      "Images existing: 3526/3526\n"
     ]
    }
   ],
   "source": [
    "# === Cell 7: sanity checks ===\n",
    "def show_basic(name, d, ycol, split_col=\"__split\"):\n",
    "    print(f\"\\n{name}: rows={len(d)}\")\n",
    "    if split_col in d:\n",
    "        print(\"Splits:\", d[split_col].value_counts().to_dict())\n",
    "    print(\"Label counts:\", d[ycol].value_counts(dropna=False).to_dict())\n",
    "\n",
    "show_basic(\"Task1\", info, \"informativeness_label\", \"__split\")\n",
    "show_basic(\"Task2\", hum, \"humanitarian_label\", \"__split\")\n",
    "show_basic(\"Task3\", dmg, \"damage_severity_label\", \"split\")\n",
    "\n",
    "# Alignment check\n",
    "a = merged.dropna(subset=[\"informativeness_label\",\"humanitarian_label\"])\n",
    "bad1 = a[(a[\"informativeness_label\"]==\"not_informative\") & (a[\"humanitarian_label\"]!=\"not_humanitarian\")]\n",
    "bad2 = a[(a[\"humanitarian_label\"]==\"not_humanitarian\") & (a[\"informativeness_label\"]!=\"not_informative\")]\n",
    "print(\"\\nAlignment violations â€” not_info->not_hum:\", len(bad1), \"| not_hum->not_info:\", len(bad2))\n",
    "\n",
    "# Image existence quick check\n",
    "def exist_ratio(df, col=\"image\", split_col=\"split\"):\n",
    "    paths = [resolve_image_path(v) for v in df[col].dropna().astype(str)]\n",
    "    ok = sum(1 for p in paths if p and p.exists())\n",
    "    print(f\"Images existing: {ok}/{len(paths)}\")\n",
    "\n",
    "info_out = info.dropna(subset=[\"informativeness_label\"]).rename(columns={\"__split\":\"split\"})\n",
    "hum_out  = hum.dropna(subset=[\"humanitarian_label\"]).rename(columns={\"__split\":\"split\"})\n",
    "\n",
    "print(\"\\nImages â€” info:\"); exist_ratio(info_out)\n",
    "print(\"Images â€” hum:\");   exist_ratio(hum_out)\n",
    "print(\"Images â€” dmg:\");   exist_ratio(dmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "179e45d3-6600-4bdb-ab8e-5fb6e59cedb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: artifacts_stage1\n"
     ]
    }
   ],
   "source": [
    "# === Cell 8: save clean CSVs ===\n",
    "info_out.to_csv(ARTIFACTS/\"task1_informative_clean.csv\", index=False)\n",
    "hum_out.to_csv(ARTIFACTS/\"task2_humanitarian_clean.csv\", index=False)\n",
    "dmg.to_csv(ARTIFACTS/\"task3_damage_clean.csv\", index=False)\n",
    "merged[[\"event_name_info\",\"tweet_id\",\"image_id\",\"text_clean_info\",\"image_info\",\n",
    "        \"informativeness_label\",\"humanitarian_label\",\"split\"]].rename(\n",
    "    columns={\"event_name_info\":\"event_name\",\"text_clean_info\":\"text_clean\",\"image_info\":\"image\"}\n",
    ").to_csv(ARTIFACTS/\"task12_merged_aligned.csv\", index=False)\n",
    "\n",
    "print(\"Saved to:\", ARTIFACTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87b7d89-effa-4502-891a-cd6c1f753750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a9e35c24d64a45a5ddb4581f702cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13608 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85675daa302f4e198ce3b7367bb4b617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387c39cfc4514f148c4eaf444b917c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2553' max='2553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2553/2553 07:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.396621</td>\n",
       "      <td>0.830130</td>\n",
       "      <td>0.781776</td>\n",
       "      <td>0.793123</td>\n",
       "      <td>0.772903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.463072</td>\n",
       "      <td>0.835494</td>\n",
       "      <td>0.783657</td>\n",
       "      <td>0.805089</td>\n",
       "      <td>0.769277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>0.544660</td>\n",
       "      <td>0.833706</td>\n",
       "      <td>0.778472</td>\n",
       "      <td>0.805734</td>\n",
       "      <td>0.761669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test: {'eval_loss': 0.43185955286026, 'eval_accuracy': 0.8444345105051408, 'eval_f1': 0.794465038177613, 'eval_precision': 0.8189214509204685, 'eval_recall': 0.7784198511166254, 'eval_runtime': 6.4699, 'eval_samples_per_second': 345.756, 'eval_steps_per_second': 10.819, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# === Cell 9: Task1 BERTweet binary ===\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import evaluate\n",
    "\n",
    "df = pd.read_csv(ARTIFACTS/\"task1_informative_clean.csv\")\n",
    "train_df = df[df[\"split\"]==\"train\"].copy()\n",
    "dev_df   = df[df[\"split\"]==\"dev\"].copy()\n",
    "test_df1 = df[df[\"split\"]==\"test\"].copy()\n",
    "\n",
    "label2id = {\"not_informative\":0, \"informative\":1}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "def to_hfds(d):\n",
    "    dd = d[[\"text_clean\",\"informativeness_label\"]].rename(columns={\"text_clean\":\"text\",\"informativeness_label\":\"label\"}).copy()\n",
    "    dd[\"label\"] = dd[\"label\"].map(label2id).astype(int)\n",
    "    return Dataset.from_pandas(dd, preserve_index=False)\n",
    "\n",
    "ds_train, ds_dev, ds_test = to_hfds(train_df), to_hfds(dev_df), to_hfds(test_df1)\n",
    "\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "def tok_fn(batch):\n",
    "    return tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "ds_train = ds_train.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "ds_dev   = ds_dev.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "ds_test  = ds_test.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "acc = evaluate.load(\"accuracy\"); f1 = evaluate.load(\"f1\"); prec = evaluate.load(\"precision\"); rec = evaluate.load(\"recall\")\n",
    "def metrics(p):\n",
    "    preds = p.predictions.argmax(1); y = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": acc.compute(predictions=preds, references=y)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=y, average=\"macro\")[\"f1\"],\n",
    "        \"precision\": prec.compute(predictions=preds, references=y, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": rec.compute(predictions=preds, references=y, average=\"macro\")[\"recall\"],\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(ARTIFACTS/\"bertweet_task1\"),\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args=args,\n",
    "    train_dataset=ds_train, eval_dataset=ds_dev,\n",
    "    tokenizer=tok, compute_metrics=metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "trainer.train()\n",
    "print(\"Task1 test:\", trainer.evaluate(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c351c003-e5b1-4f00-b318-a8d9ffb29cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2bd0b43e1447caa0b3b70dc424a602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13608 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8306ccdb714e4ec596a39a36f83dc6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcadb8c70e24407a776b4e75ef44c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3404' max='3404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3404/3404 10:32, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.772900</td>\n",
       "      <td>2.592832</td>\n",
       "      <td>0.351810</td>\n",
       "      <td>0.426841</td>\n",
       "      <td>0.535589</td>\n",
       "      <td>0.542219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.732600</td>\n",
       "      <td>2.549014</td>\n",
       "      <td>0.415735</td>\n",
       "      <td>0.468205</td>\n",
       "      <td>0.554016</td>\n",
       "      <td>0.612840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.510600</td>\n",
       "      <td>2.612000</td>\n",
       "      <td>0.430040</td>\n",
       "      <td>0.467679</td>\n",
       "      <td>0.542219</td>\n",
       "      <td>0.578036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.554400</td>\n",
       "      <td>2.637512</td>\n",
       "      <td>0.419759</td>\n",
       "      <td>0.458099</td>\n",
       "      <td>0.528189</td>\n",
       "      <td>0.580386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task2 test: {'eval_loss': 2.6465365886688232, 'eval_accuracy': 0.42378185069289226, 'eval_f1_macro': 0.48169811806435764, 'eval_precision_macro': 0.561627458425163, 'eval_recall_macro': 0.5875926975509332, 'eval_runtime': 6.6591, 'eval_samples_per_second': 335.932, 'eval_steps_per_second': 10.512, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# === Cell 10: Task2 BERTweet multiclass (class-weighted) ===\n",
    "from collections import Counter\n",
    "from transformers import Trainer\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv(ARTIFACTS/\"task2_humanitarian_clean.csv\")\n",
    "train_df = df[df[\"split\"]==\"train\"].copy()\n",
    "dev_df   = df[df[\"split\"]==\"dev\"].copy()\n",
    "test_df2 = df[df[\"split\"]==\"test\"].copy()\n",
    "\n",
    "classes = sorted(df[\"humanitarian_label\"].dropna().unique().tolist())\n",
    "label2id = {c:i for i,c in enumerate(classes)}\n",
    "id2label = {i:c for c,i in label2id.items()}\n",
    "\n",
    "def to_hfds(d):\n",
    "    dd = d[[\"text_clean\",\"humanitarian_label\"]].rename(columns={\"text_clean\":\"text\",\"humanitarian_label\":\"label\"}).copy()\n",
    "    dd[\"label\"] = dd[\"label\"].map(label2id).astype(int)\n",
    "    return Dataset.from_pandas(dd, preserve_index=False)\n",
    "\n",
    "ds_train, ds_dev, ds_test = to_hfds(train_df), to_hfds(dev_df), to_hfds(test_df2)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=True)\n",
    "def tok_fn(b): return tok(b[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "ds_train = ds_train.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "ds_dev   = ds_dev.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "ds_test  = ds_test.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"vinai/bertweet-base\", num_labels=len(classes), id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "# class weights from TRAIN distribution\n",
    "cnt = Counter(train_df[\"humanitarian_label\"])\n",
    "weights = torch.tensor([len(train_df)/max(1, cnt[id2label[i]]) for i in range(len(classes))], dtype=torch.float)\n",
    "weights = weights / weights.mean()\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = CrossEntropyLoss(weight=weights.to(logits.device), label_smoothing=0.05)\n",
    "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "acc = evaluate.load(\"accuracy\"); f1 = evaluate.load(\"f1\")\n",
    "prec = evaluate.load(\"precision\"); rec = evaluate.load(\"recall\")\n",
    "def metrics(p):\n",
    "    preds = p.predictions.argmax(1); y = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": acc.compute(predictions=preds, references=y)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=y, average=\"macro\")[\"f1\"],\n",
    "        \"precision_macro\": prec.compute(predictions=preds, references=y, average=\"macro\")[\"precision\"],\n",
    "        \"recall_macro\": rec.compute(predictions=preds, references=y, average=\"macro\")[\"recall\"],\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(ARTIFACTS/\"bertweet_task2\"),\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer2 = WeightedTrainer(\n",
    "    model=model, args=args,\n",
    "    train_dataset=ds_train, eval_dataset=ds_dev,\n",
    "    tokenizer=tok, compute_metrics=metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "trainer2.train()\n",
    "print(\"Task2 test:\", trainer2.evaluate(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0ee027-2b9e-4fd5-87fc-8c0cffa98135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoise: kept Positive agreement rows in TRAIN: 6126/13608\n",
      "Classes: ['affected_individuals', 'infrastructure_and_utility_damage', 'injured_or_dead_people', 'missing_or_found_people', 'not_humanitarian', 'other_relevant_information', 'rescue_volunteering_or_donation_effort', 'vehicle_damage']\n",
      "Upsampled class counts: {'not_humanitarian': 3000, 'other_relevant_information': 3000, 'rescue_volunteering_or_donation_effort': 3000, 'infrastructure_and_utility_damage': 3000, 'affected_individuals': 3000, 'injured_or_dead_people': 3000, 'vehicle_damage': 3000, 'missing_or_found_people': 3000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51d5e3e5be54833908a6125d9b825cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5e8ebb1ba1497b9baf8db11718df8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a69c3e09674abb9993ac35547e61d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {'affected_individuals': 0.33023539185523987, 'infrastructure_and_utility_damage': 0.11507295072078705, 'injured_or_dead_people': 0.3226727545261383, 'missing_or_found_people': 4.372772216796875, 'not_humanitarian': 0.03194216638803482, 'other_relevant_information': 0.026325596496462822, 'rescue_volunteering_or_donation_effort': 0.04423103854060173, 'vehicle_damage': 2.7567477226257324}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9000/9000 32:34, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.761319</td>\n",
       "      <td>0.666518</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.534388</td>\n",
       "      <td>0.549219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>1.029746</td>\n",
       "      <td>0.660706</td>\n",
       "      <td>0.532834</td>\n",
       "      <td>0.566249</td>\n",
       "      <td>0.544579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>1.314310</td>\n",
       "      <td>0.664730</td>\n",
       "      <td>0.525351</td>\n",
       "      <td>0.543499</td>\n",
       "      <td>0.534102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>1.625590</td>\n",
       "      <td>0.642378</td>\n",
       "      <td>0.537486</td>\n",
       "      <td>0.556548</td>\n",
       "      <td>0.564011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.606519</td>\n",
       "      <td>0.658918</td>\n",
       "      <td>0.526813</td>\n",
       "      <td>0.536668</td>\n",
       "      <td>0.553559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.663839</td>\n",
       "      <td>0.644166</td>\n",
       "      <td>0.529466</td>\n",
       "      <td>0.550816</td>\n",
       "      <td>0.545366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task2 (even more) â€” test: {'eval_loss': 1.6846615076065063, 'eval_accuracy': 0.6267322306660706, 'eval_f1_macro': 0.5347430619056721, 'eval_precision_macro': 0.5504205660034962, 'eval_recall_macro': 0.5711941849520272, 'eval_runtime': 8.7782, 'eval_samples_per_second': 254.837, 'eval_steps_per_second': 7.974, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "# === Task 2 (Humanitarian) â€” \"Even More\" cell ===\n",
    "# - Model swap: CardiffNLP Twitter-RoBERTa or BERTweet\n",
    "# - Denoised training: keep only rows with label_text_image == \"Positive\" (train split only)\n",
    "# - Upsampling + FocalLoss + cosine warmup\n",
    "\n",
    "# %pip install --quiet emoji==0.6.0  # recommended for BERTweet normalization (safe to skip for RoBERTa)\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from collections import Counter\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "                          get_cosine_schedule_with_warmup)\n",
    "import evaluate\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "\n",
    "# ======= TOGGLES =======\n",
    "MODEL_NAME     = \"cardiffnlp/twitter-roberta-base\"   # or: \"vinai/bertweet-base\"\n",
    "DENOISE_TRAIN  = True                                # True = keep only label_text_image == \"Positive\" in TRAIN\n",
    "TARGET_PER_CLASS = 3000                              # upsample target per class (cap)\n",
    "MAX_LEN        = 160\n",
    "EPOCHS         = 6\n",
    "BATCH_TRAIN    = 16\n",
    "BATCH_EVAL     = 32\n",
    "LR             = 2e-5\n",
    "WARMUP_RATIO   = 0.10\n",
    "LABEL_SMOOTH   = 0.02\n",
    "FOCAL_GAMMA    = 2.0\n",
    "# =======================\n",
    "\n",
    "ARTIFACTS = Path(\"./artifacts_stage1\")\n",
    "clean_csv = ARTIFACTS/\"task2_humanitarian_clean.csv\"\n",
    "assert clean_csv.exists(), f\"Missing {clean_csv}. Run the data prep cells first.\"\n",
    "\n",
    "# --- Load clean split-aware CSV\n",
    "df_clean = pd.read_csv(clean_csv)\n",
    "train_df = df_clean[df_clean[\"split\"]==\"train\"].copy()\n",
    "dev_df   = df_clean[df_clean[\"split\"]==\"dev\"].copy()\n",
    "test_df  = df_clean[df_clean[\"split\"]==\"test\"].copy()\n",
    "\n",
    "# --- Optionally denoise TRAIN: join back to raw TSV to read label_text_image\n",
    "def read_tsv_robust(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=\"\\t\", engine=\"python\",\n",
    "                           quoting=csv.QUOTE_NONE, escapechar=\"\\\\\",\n",
    "                           on_bad_lines=\"skip\", encoding=\"utf-8\", encoding_errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, sep=\"\\t\", engine=\"python\", on_bad_lines=\"skip\", encoding=\"latin-1\")\n",
    "\n",
    "def load_task_hum_raw(data_root: Path) -> pd.DataFrame:\n",
    "    split_dir = data_root / \"crisismmd_datasplit_all\" / \"crisismmd_datasplit_all\"\n",
    "    frames = []\n",
    "    for split in (\"train\",\"dev\",\"test\"):\n",
    "        p = split_dir / f\"task_humanitarian_text_img_{split}.tsv\"\n",
    "        if not p.exists(): \n",
    "            continue\n",
    "        df = read_tsv_robust(p)\n",
    "        df[\"__split\"] = split\n",
    "        frames.append(df)\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.concat(frames, ignore_index=True, sort=False)\n",
    "    # Make sure the key columns exist with expected names\n",
    "    df = df.rename(columns={\n",
    "        \"tweet_id\":\"tweet_id\",\n",
    "        \"image_id\":\"image_id\",\n",
    "        \"label_text_image\":\"label_text_image\"\n",
    "    })\n",
    "    return df[[\"tweet_id\",\"image_id\",\"label_text_image\",\"__split\"]]\n",
    "\n",
    "if DENOISE_TRAIN:\n",
    "    # >>> UPDATE path if your dataset lives elsewhere <<<\n",
    "    DATA_ROOT = Path(r\"C:\\JP_Notebooks\\CSCE 5380\\Project\\CrisisMMD_v2.0\")\n",
    "    raw_hum = load_task_hum_raw(DATA_ROOT)\n",
    "    assert len(raw_hum), \"Could not load raw humanitarian TSVs to get label_text_image.\"\n",
    "    # Merge only TRAIN rows\n",
    "    train_df = train_df.merge(\n",
    "        raw_hum[raw_hum[\"__split\"]==\"train\"][[\"tweet_id\",\"image_id\",\"label_text_image\"]],\n",
    "        on=[\"tweet_id\",\"image_id\"], how=\"left\"\n",
    "    )\n",
    "    before = len(train_df)\n",
    "    train_df = train_df[ train_df[\"label_text_image\"].astype(str).str.lower() == \"positive\" ].copy()\n",
    "    after = len(train_df)\n",
    "    print(f\"Denoise: kept Positive agreement rows in TRAIN: {after}/{before}\")\n",
    "    train_df = train_df.drop(columns=[\"label_text_image\"], errors=\"ignore\")\n",
    "\n",
    "# --- Label space\n",
    "classes = sorted(df_clean[\"humanitarian_label\"].dropna().unique().tolist())\n",
    "label2id = {c:i for i,c in enumerate(classes)}\n",
    "id2label = {i:c for c,i in label2id.items()}\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "# --- Upsample TRAIN to balance classes\n",
    "counts = train_df[\"humanitarian_label\"].value_counts().to_dict()\n",
    "max_c  = max(counts.values()) if counts else 0\n",
    "target = min(max_c, TARGET_PER_CLASS) if max_c else TARGET_PER_CLASS\n",
    "frames = []\n",
    "rng = np.random.default_rng(42)\n",
    "for cls, cnt in counts.items():\n",
    "    part = train_df[train_df[\"humanitarian_label\"]==cls]\n",
    "    if cnt >= target:\n",
    "        frames.append(part.sample(n=target, random_state=42))\n",
    "    else:\n",
    "        idx = rng.choice(part.index.values, size=target, replace=True)\n",
    "        frames.append(part.loc[idx])\n",
    "train_up = pd.concat(frames, ignore_index=True) if frames else train_df.copy()\n",
    "print(\"Upsampled class counts:\", train_up[\"humanitarian_label\"].value_counts().to_dict())\n",
    "\n",
    "# --- HF datasets\n",
    "def to_hfds(d):\n",
    "    dd = d[[\"text_clean\",\"humanitarian_label\"]].rename(columns={\"text_clean\":\"text\",\"humanitarian_label\":\"label\"}).copy()\n",
    "    dd[\"label\"] = dd[\"label\"].map(label2id).astype(int)\n",
    "    return Dataset.from_pandas(dd, preserve_index=False)\n",
    "\n",
    "ds_train, ds_dev, ds_test = to_hfds(train_up), to_hfds(dev_df), to_hfds(test_df)\n",
    "\n",
    "# --- Tokenizer\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def tok_fn(batch):\n",
    "    return tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "\n",
    "ds_train = ds_train.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "ds_dev   = ds_dev.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "ds_test  = ds_test.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "\n",
    "# --- Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=len(classes), id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "# --- Class weights (from ORIGINAL, un-upsampled TRAIN)\n",
    "cnt = Counter(df_clean[df_clean[\"split\"]==\"train\"][\"humanitarian_label\"])\n",
    "w_vec = torch.tensor([len(df_clean[df_clean[\"split\"]==\"train\"])/max(1, cnt[id2label[i]]) for i in range(len(classes))], dtype=torch.float)\n",
    "w_vec = w_vec / w_vec.mean()\n",
    "print(\"Class weights:\", {id2label[i]: float(w_vec[i]) for i in range(len(classes))})\n",
    "\n",
    "# --- Focal Loss + tiny label smoothing\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ls = label_smoothing\n",
    "    def forward(self, logits, targets):\n",
    "        if self.ls and self.ls > 0:\n",
    "            n = logits.size(-1)\n",
    "            smoothed = torch.full_like(logits, self.ls/(n-1))\n",
    "            smoothed.scatter_(1, targets.unsqueeze(1), 1.0 - self.ls)\n",
    "            log_probs = logits.log_softmax(dim=-1)\n",
    "            ce = -(smoothed * log_probs).sum(dim=-1)\n",
    "        else:\n",
    "            ce = F.cross_entropy(logits, targets, weight=self.alpha, reduction=\"none\")\n",
    "        pt = torch.exp(-ce)\n",
    "        loss = ((1-pt)**self.gamma) * ce\n",
    "        return loss.mean()\n",
    "\n",
    "criterion = FocalLoss(alpha=w_vec, gamma=FOCAL_GAMMA, label_smoothing=LABEL_SMOOTH)\n",
    "\n",
    "# --- Metrics\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "f1  = evaluate.load(\"f1\")\n",
    "prec= evaluate.load(\"precision\")\n",
    "rec = evaluate.load(\"recall\")\n",
    "def metrics(p):\n",
    "    preds = p.predictions.argmax(1); y = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": acc.compute(predictions=preds, references=y)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=y, average=\"macro\")[\"f1\"],\n",
    "        \"precision_macro\": prec.compute(predictions=preds, references=y, average=\"macro\")[\"precision\"],\n",
    "        \"recall_macro\": rec.compute(predictions=preds, references=y, average=\"macro\")[\"recall\"],\n",
    "    }\n",
    "\n",
    "# --- Training args (use new 'eval_strategy' on newer transformers, but 'evaluation_strategy' still works)\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(ARTIFACTS/\"task2_even_more\"),\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=LR,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# --- Custom Trainer: focal loss + cosine schedule\n",
    "class FocalTrainer(Trainer):\n",
    "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
    "        super().create_optimizer_and_scheduler(num_training_steps)\n",
    "        self.lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=int(num_training_steps * args.warmup_ratio),\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits  = outputs.get(\"logits\")\n",
    "        loss = criterion(logits, labels.to(logits.device))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = FocalTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_dev,\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"Task2 (even more) â€” test:\", trainer.evaluate(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7436d6ad-a727-4352-8ef8-19e2fdde6fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT exists: True\n",
      "IMG_ROOT exists: True\n",
      "Sample resolved path: C:\\JP_Notebooks\\CSCE 5380\\Project\\CrisisMMD_v2.0\\data_image\\hurricane_harvey\\8_9_2017\\905960092822003712_0.jpg\n",
      "Counts by split: {'train': 2468, 'dev': 529, 'test': 529}\n",
      "Label counts (train): {'severe': 1548, 'mild': 587, 'little_or_none': 333}\n",
      "Class weights: {'little_or_none': 1.6831165552139282, 'mild': 0.9548173546791077, 'severe': 0.36206579208374023}\n",
      "=== Task3 training start (robust) ===\n",
      "\n",
      "Epoch 1/6\n",
      "  [train]   10/78 | loss 0.5698 | acc 0.328 | 12.2s\n",
      "  [train]   20/78 | loss 0.4407 | acc 0.292 | 18.8s\n",
      "  [train]   30/78 | loss 0.3850 | acc 0.263 | 25.5s\n",
      "  [train]   40/78 | loss 0.3530 | acc 0.246 | 31.9s\n",
      "  [train]   50/78 | loss 0.3368 | acc 0.232 | 38.2s\n",
      "  [train]   60/78 | loss 0.3280 | acc 0.245 | 44.8s\n",
      "  [train]   70/78 | loss 0.3185 | acc 0.237 | 51.5s\n",
      "  [train]   78/78 | loss 0.3121 | acc 0.241 | 59.1s\n",
      "  [valid]   10/17 | loss 0.2415 | acc 0.294 | 5.4s\n",
      "  [valid]   17/17 | loss 0.2527 | acc 0.297 | 10.5s\n",
      ">> Epoch 1 | train 0.3121/0.241 | valid 0.2527/0.297\n",
      "  * new best model\n",
      "\n",
      "Epoch 2/6\n",
      "  [train]   10/78 | loss 0.2473 | acc 0.419 | 4.1s\n",
      "  [train]   20/78 | loss 0.2212 | acc 0.438 | 8.6s\n",
      "  [train]   30/78 | loss 0.2106 | acc 0.441 | 13.0s\n",
      "  [train]   40/78 | loss 0.2156 | acc 0.430 | 16.9s\n",
      "  [train]   50/78 | loss 0.2193 | acc 0.419 | 20.8s\n",
      "  [train]   60/78 | loss 0.2211 | acc 0.406 | 24.8s\n",
      "  [train]   70/78 | loss 0.2167 | acc 0.398 | 28.8s\n",
      "  [train]   78/78 | loss 0.2181 | acc 0.393 | 31.8s\n",
      "  [valid]   10/17 | loss 0.2328 | acc 0.466 | 2.7s\n",
      "  [valid]   17/17 | loss 0.2407 | acc 0.448 | 4.6s\n",
      ">> Epoch 2 | train 0.2181/0.393 | valid 0.2407/0.448\n",
      "  * new best model\n",
      "\n",
      "Epoch 3/6\n",
      "  [train]   10/78 | loss 0.1623 | acc 0.559 | 4.2s\n",
      "  [train]   20/78 | loss 0.1695 | acc 0.559 | 8.3s\n",
      "  [train]   30/78 | loss 0.1551 | acc 0.576 | 12.4s\n",
      "  [train]   40/78 | loss 0.1591 | acc 0.567 | 16.5s\n",
      "  [train]   50/78 | loss 0.1600 | acc 0.560 | 20.6s\n",
      "  [train]   60/78 | loss 0.1635 | acc 0.543 | 24.6s\n",
      "  [train]   70/78 | loss 0.1683 | acc 0.542 | 28.8s\n",
      "  [train]   78/78 | loss 0.1684 | acc 0.531 | 31.7s\n",
      "  [valid]   10/17 | loss 0.2517 | acc 0.534 | 2.6s\n",
      "  [valid]   17/17 | loss 0.2694 | acc 0.527 | 4.5s\n",
      ">> Epoch 3 | train 0.1684/0.531 | valid 0.2694/0.527\n",
      "  (no improvement) 1/2\n",
      "\n",
      "Epoch 4/6\n",
      "  [train]   10/78 | loss 0.1021 | acc 0.728 | 4.3s\n",
      "  [train]   20/78 | loss 0.1120 | acc 0.652 | 8.3s\n",
      "  [train]   30/78 | loss 0.1167 | acc 0.675 | 12.2s\n",
      "  [train]   40/78 | loss 0.1108 | acc 0.679 | 16.3s\n",
      "  [train]   50/78 | loss 0.1128 | acc 0.658 | 20.3s\n",
      "  [train]   60/78 | loss 0.1145 | acc 0.658 | 24.2s\n",
      "  [train]   70/78 | loss 0.1170 | acc 0.646 | 28.1s\n",
      "  [train]   78/78 | loss 0.1173 | acc 0.654 | 31.0s\n",
      "  [valid]   10/17 | loss 0.3556 | acc 0.472 | 2.6s\n",
      "  [valid]   17/17 | loss 0.3698 | acc 0.499 | 4.5s\n",
      ">> Epoch 4 | train 0.1173/0.654 | valid 0.3698/0.499\n",
      "  (no improvement) 2/2\n",
      "Early stopping.\n",
      "\n",
      "Task3 â€” Test report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "little_or_none       0.51      0.52      0.51        71\n",
      "          mild       0.33      0.77      0.47       126\n",
      "        severe       0.89      0.44      0.59       332\n",
      "\n",
      "      accuracy                           0.53       529\n",
      "     macro avg       0.58      0.58      0.52       529\n",
      "  weighted avg       0.70      0.53      0.55       529\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 37  30   4]\n",
      " [ 14  97  15]\n",
      " [ 22 163 147]]\n",
      "Saved artifacts to: artifacts_stage1\\convnext_tiny_task3_robust\n"
     ]
    }
   ],
   "source": [
    "# === Task 3 (Damage) â€” robust image resolver + ConvNeXt-Tiny + FocalLoss ===\n",
    "import time, math\n",
    "from collections import Counter\n",
    "from PIL import Image, ImageOps\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ---------- 0) Paths, load CSV ----------\n",
    "ARTIFACTS = Path(\"./artifacts_stage1\")\n",
    "csv_path = ARTIFACTS / \"task3_damage_clean.csv\"\n",
    "assert csv_path.exists(), f\"Missing {csv_path}. Run the prep cells first.\"\n",
    "\n",
    "# >>> UPDATE THIS if your dataset lives elsewhere <<<\n",
    "DATA_ROOT = Path(r\"C:\\JP_Notebooks\\CSCE 5380\\Project\\CrisisMMD_v2.0\")\n",
    "IMG_ROOT  = DATA_ROOT / \"data_image\"\n",
    "print(\"DATA_ROOT exists:\", DATA_ROOT.exists())\n",
    "print(\"IMG_ROOT exists:\", IMG_ROOT.exists())\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ---------- 1) Resolve image paths robustly ----------\n",
    "def resolve_image_path(relpath: str) -> Path | None:\n",
    "    if not isinstance(relpath, str) or relpath.strip() == \"\":\n",
    "        return None\n",
    "    s = relpath.replace(\"\\\\\", \"/\").lstrip(\"./\")\n",
    "    p = Path(s)\n",
    "    # absolute?\n",
    "    if p.is_absolute():\n",
    "        return p if p.exists() else None\n",
    "    # starts with data_image/...\n",
    "    if s.lower().startswith(\"data_image/\"):\n",
    "        cand = (DATA_ROOT / s).resolve()\n",
    "    else:\n",
    "        cand = (IMG_ROOT / s).resolve()\n",
    "    return cand if cand.exists() else None\n",
    "\n",
    "df[\"abs_image\"] = df[\"image\"].map(resolve_image_path)\n",
    "missing = df[\"abs_image\"].isna().sum()\n",
    "if missing:\n",
    "    print(f\"Warning: dropping {missing} rows with missing image files.\")\n",
    "df = df[~df[\"abs_image\"].isna()].reset_index(drop=True)\n",
    "\n",
    "# Show a couple of examples\n",
    "print(\"Sample resolved path:\", df.loc[0, \"abs_image\"])\n",
    "\n",
    "# ---------- 2) Splits and labels ----------\n",
    "train_df = df[df[\"split\"]==\"train\"].reset_index(drop=True)\n",
    "dev_df   = df[df[\"split\"]==\"dev\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"]==\"test\"].reset_index(drop=True)\n",
    "\n",
    "label2id = {\"little_or_none\":0, \"mild\":1, \"severe\":2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "print(\"Counts by split:\", {\"train\": len(train_df), \"dev\": len(dev_df), \"test\": len(test_df)})\n",
    "print(\"Label counts (train):\", train_df[\"damage_severity_label\"].value_counts().to_dict())\n",
    "\n",
    "# ---------- 3) Dataset & transforms ----------\n",
    "IMG_SIZE = 224\n",
    "train_tf = T.Compose([\n",
    "    T.RandomResizedCrop(IMG_SIZE, scale=(0.85, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomApply([T.ColorJitter(0.2,0.2,0.2,0.05)], p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "eval_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class DamageImageDS(Dataset):\n",
    "    def __init__(self, frame, transform):\n",
    "        self.df = frame.reset_index(drop=True)\n",
    "        self.t = transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        img_path = r[\"abs_image\"]\n",
    "        # extra guard (shouldn't trigger after filtering)\n",
    "        if img_path is None or not Path(img_path).exists():\n",
    "            raise FileNotFoundError(f\"Image missing at index {i}: {img_path}\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = self.t(img)\n",
    "        y = label2id[r[\"damage_severity_label\"]]\n",
    "        return x, y\n",
    "\n",
    "train_ds = DamageImageDS(train_df, train_tf)\n",
    "dev_ds   = DamageImageDS(dev_df,   eval_tf)\n",
    "test_ds  = DamageImageDS(test_df,  eval_tf)\n",
    "\n",
    "# DataLoaders\n",
    "BATCH = 32\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=False, persistent_workers=False)\n",
    "dev_dl   = DataLoader(dev_ds,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=False, persistent_workers=False)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=False, persistent_workers=False)\n",
    "\n",
    "# ---------- 4) Model, loss, optimizer ----------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "\n",
    "backbone_name = \"convnext_tiny.fb_in22k_ft_in1k\"\n",
    "model = timm.create_model(backbone_name, pretrained=True, num_classes=3).to(device)\n",
    "\n",
    "# Class weights from TRAIN distribution\n",
    "cnt = Counter(train_df[\"damage_severity_label\"])\n",
    "weights_vec = torch.tensor([len(train_df)/cnt[id2label[i]] for i in range(3)], dtype=torch.float)\n",
    "weights_vec = weights_vec / weights_vec.mean()\n",
    "print(\"Class weights:\", {id2label[i]: float(weights_vec[i]) for i in range(3)})\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, logits, targets):\n",
    "        ce = F.cross_entropy(logits, targets, weight=self.alpha, reduction=\"none\")\n",
    "        pt = torch.exp(-ce)\n",
    "        return ((1-pt)**self.gamma * ce).mean()\n",
    "\n",
    "criterion = FocalLoss(alpha=weights_vec.to(device), gamma=2.0)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler(device.type, enabled=torch.cuda.is_available())\n",
    "\n",
    "# ---------- 5) Training with prints + early stopping ----------\n",
    "def run_epoch(dl, train=True):\n",
    "    model.train(train)\n",
    "    total_loss, total, correct = 0.0, 0, 0\n",
    "    t0 = time.time()\n",
    "    for i, (x,y) in enumerate(dl, 1):\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast(device_type=device.type, enabled=torch.cuda.is_available()):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            with torch.no_grad(), autocast(device_type=device.type, enabled=torch.cuda.is_available()):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "        total_loss += float(loss) * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "        if i % 10 == 0 or i == len(dl):\n",
    "            print(f\"  [{'train' if train else 'valid'}] {i:4d}/{len(dl)} | loss {total_loss/total:.4f} | acc {correct/total:.3f} | {time.time()-t0:.1f}s\")\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "EPOCHS = 6; patience = 2\n",
    "best_val = math.inf; best_state=None; no_improve=0\n",
    "print(\"=== Task3 training start (robust) ===\")\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    print(f\"\\nEpoch {ep}/{EPOCHS}\")\n",
    "    tr_loss, tr_acc = run_epoch(train_dl, train=True)\n",
    "    va_loss, va_acc = run_epoch(dev_dl,   train=False)\n",
    "    print(f\">> Epoch {ep} | train {tr_loss:.4f}/{tr_acc:.3f} | valid {va_loss:.4f}/{va_acc:.3f}\")\n",
    "    if va_loss < best_val - 1e-4:\n",
    "        best_val = va_loss; best_state = dict(model.state_dict()); no_improve=0\n",
    "        print(\"  * new best model\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        print(f\"  (no improvement) {no_improve}/{patience}\")\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping.\"); break\n",
    "\n",
    "if best_state: model.load_state_dict(best_state)\n",
    "\n",
    "# ---------- 6) Test evaluation ----------\n",
    "all_y, all_p = [], []\n",
    "model.eval()\n",
    "with torch.no_grad(), autocast(device_type=device.type, enabled=torch.cuda.is_available()):\n",
    "    for x,y in test_dl:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        all_p.append(logits.argmax(1).cpu().numpy())\n",
    "        all_y.append(y.numpy())\n",
    "all_p = np.concatenate(all_p); all_y = np.concatenate(all_y)\n",
    "print(\"\\nTask3 â€” Test report:\\n\", classification_report(all_y, all_p, target_names=[id2label[i] for i in range(3)]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(all_y, all_p))\n",
    "\n",
    "# ---------- 7) Save artifacts ----------\n",
    "save_dir = ARTIFACTS / \"convnext_tiny_task3_robust\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), save_dir / \"model.pt\")\n",
    "pd.DataFrame({\n",
    "    \"tweet_id\": test_df[\"tweet_id\"],\n",
    "    \"image_id\": test_df[\"image_id\"],\n",
    "    \"true_label\": [id2label[i] for i in all_y],\n",
    "    \"pred_label\": [id2label[i] for i in all_p],\n",
    "}).to_csv(save_dir / \"test_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Saved artifacts to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81180bea-4407-4f5e-81f9-240ae5f38f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stronger image training (macro-F1 early stop) ===\n",
      "Ep 01 | train 0.3290/0.436/F1m 0.366 | val 0.2569/0.380/F1m 0.359\n",
      "  * new best by macro-F1\n",
      "Ep 02 | train 0.1756/0.631/F1m 0.590 | val 0.2863/0.414/F1m 0.402\n",
      "  * new best by macro-F1\n",
      "Ep 03 | train 0.1003/0.749/F1m 0.726 | val 0.3217/0.457/F1m 0.427\n",
      "  * new best by macro-F1\n",
      "Ep 04 | train 0.0665/0.783/F1m 0.771 | val 0.4764/0.594/F1m 0.498\n",
      "  * new best by macro-F1\n",
      "Ep 05 | train 0.0609/0.823/F1m 0.816 | val 0.4089/0.529/F1m 0.495\n",
      "Ep 06 | train 0.0394/0.859/F1m 0.853 | val 0.4694/0.595/F1m 0.530\n",
      "  * new best by macro-F1\n",
      "Ep 07 | train 0.0425/0.880/F1m 0.878 | val 0.4553/0.541/F1m 0.490\n",
      "Ep 08 | train 0.0285/0.894/F1m 0.890 | val 0.5057/0.586/F1m 0.524\n",
      "\n",
      "Stronger image â€” Test report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "little_or_none       0.41      0.55      0.47        71\n",
      "          mild       0.38      0.56      0.45       126\n",
      "        severe       0.85      0.64      0.73       332\n",
      "\n",
      "      accuracy                           0.61       529\n",
      "     macro avg       0.55      0.58      0.55       529\n",
      "  weighted avg       0.68      0.61      0.63       529\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 39  22  10]\n",
      " [ 28  70  28]\n",
      " [ 28  92 212]]\n",
      "Saved image probs to: artifacts_stage1\\task3_img_probs.npy\n"
     ]
    }
   ],
   "source": [
    "# === Stronger Task-3 image baseline (IMG_SIZE=288, sampler, macro-F1 early stop) ===\n",
    "import time, math\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Paths\n",
    "ARTIFACTS = Path(\"./artifacts_stage1\")\n",
    "df = pd.read_csv(ARTIFACTS/\"task3_damage_clean.csv\")\n",
    "\n",
    "# Resolve absolute paths (reuse what you used before)\n",
    "DATA_ROOT = Path(r\"C:\\JP_Notebooks\\CSCE 5380\\Project\\CrisisMMD_v2.0\")\n",
    "IMG_ROOT  = DATA_ROOT / \"data_image\"\n",
    "def resolve_image_path(relpath: str):\n",
    "    if not isinstance(relpath, str) or relpath.strip()==\"\":\n",
    "        return None\n",
    "    s = relpath.replace(\"\\\\\",\"/\").lstrip(\"./\")\n",
    "    p = (DATA_ROOT / s) if s.lower().startswith(\"data_image/\") else (IMG_ROOT / s)\n",
    "    p = p.resolve()\n",
    "    return p if p.exists() else None\n",
    "\n",
    "df[\"abs_image\"] = df[\"image\"].map(resolve_image_path)\n",
    "df = df[~df[\"abs_image\"].isna()].reset_index(drop=True)\n",
    "\n",
    "# Splits/labels\n",
    "train_df = df[df[\"split\"]==\"train\"].reset_index(drop=True)\n",
    "dev_df   = df[df[\"split\"]==\"dev\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"]==\"test\"].reset_index(drop=True)\n",
    "\n",
    "label2id = {\"little_or_none\":0, \"mild\":1, \"severe\":2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "# Dataset\n",
    "IMG_SIZE = 288\n",
    "train_tf = T.Compose([\n",
    "    T.RandomResizedCrop(IMG_SIZE, scale=(0.80, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomApply([T.ColorJitter(0.25,0.25,0.25,0.05)], p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "eval_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "class DamageImageDS(Dataset):\n",
    "    def __init__(self, frame, transform):\n",
    "        self.df = frame.reset_index(drop=True)\n",
    "        self.t = transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        x = self.t(Image.open(r[\"abs_image\"]).convert(\"RGB\"))\n",
    "        y = label2id[r[\"damage_severity_label\"]]\n",
    "        return x, y\n",
    "\n",
    "train_ds = DamageImageDS(train_df, train_tf)\n",
    "dev_ds   = DamageImageDS(dev_df,   eval_tf)\n",
    "test_ds  = DamageImageDS(test_df,  eval_tf)\n",
    "\n",
    "# Balanced sampler (per-sample weight from inverse class frequency)\n",
    "cnt = Counter(train_df[\"damage_severity_label\"])\n",
    "class_w = torch.tensor([len(train_df)/cnt[id2label[i]] for i in range(3)], dtype=torch.float)\n",
    "class_w = class_w / class_w.mean()\n",
    "y_train = train_df[\"damage_severity_label\"].map(label2id).to_numpy()\n",
    "sample_w = np.array([class_w[i].item() for i in y_train], dtype=np.float32)\n",
    "sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
    "\n",
    "BATCH = 24  # IMG_SIZE=288 uses more VRAM;\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, sampler=sampler, num_workers=0)\n",
    "dev_dl   = DataLoader(dev_ds,   batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "\n",
    "# Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "\n",
    "backbone = \"convnext_tiny.fb_in22k_ft_in1k\"  # strong & fast\n",
    "model = timm.create_model(backbone, pretrained=True, num_classes=3).to(device)\n",
    "\n",
    "# Focal loss with class weights\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, logits, targets):\n",
    "        ce = F.cross_entropy(logits, targets, weight=self.alpha, reduction=\"none\")\n",
    "        pt = torch.exp(-ce)\n",
    "        return ((1-pt)**self.gamma * ce).mean()\n",
    "\n",
    "criterion = FocalLoss(alpha=class_w.to(device), gamma=2.0)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler(device.type, enabled=torch.cuda.is_available())\n",
    "\n",
    "def run_epoch(dl, train=True):\n",
    "    model.train(train)\n",
    "    total_loss, total, correct = 0.0, 0, 0\n",
    "    all_logits, all_y = [], []\n",
    "    for i, (x,y) in enumerate(dl, 1):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast(device_type=device.type, enabled=torch.cuda.is_available()):\n",
    "                logits = model(x); loss = criterion(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "        else:\n",
    "            with torch.no_grad(), autocast(device_type=device.type, enabled=torch.cuda.is_available()):\n",
    "                logits = model(x); loss = criterion(logits, y)\n",
    "        total_loss += float(loss) * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "        all_logits.append(logits.detach().cpu()); all_y.append(y.detach().cpu())\n",
    "    all_logits = torch.cat(all_logits).numpy()\n",
    "    all_y = torch.cat(all_y).numpy()\n",
    "    macro_f1 = f1_score(all_y, all_logits.argmax(1), average=\"macro\")\n",
    "    return total_loss/total, correct/total, macro_f1\n",
    "\n",
    "EPOCHS, patience = 8, 3\n",
    "best_f1, best_state, no_imp = -1.0, None, 0\n",
    "print(\"=== Stronger image training (macro-F1 early stop) ===\")\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc, tr_f1 = run_epoch(train_dl, train=True)\n",
    "    va_loss, va_acc, va_f1 = run_epoch(dev_dl,   train=False)\n",
    "    print(f\"Ep {ep:02d} | train {tr_loss:.4f}/{tr_acc:.3f}/F1m {tr_f1:.3f} | val {va_loss:.4f}/{va_acc:.3f}/F1m {va_f1:.3f}\")\n",
    "    if va_f1 > best_f1 + 1e-4:\n",
    "        best_f1, best_state, no_imp = va_f1, dict(model.state_dict()), 0\n",
    "        print(\"  * new best by macro-F1\")\n",
    "    else:\n",
    "        no_imp += 1\n",
    "        if no_imp >= patience:\n",
    "            print(\"Early stopping.\"); break\n",
    "if best_state: model.load_state_dict(best_state)\n",
    "\n",
    "# Test\n",
    "def collect_probs(dl):\n",
    "    model.eval()\n",
    "    probs, ys = [], []\n",
    "    with torch.no_grad(), autocast(device_type=device.type, enabled=torch.cuda.is_available()):\n",
    "        for x,y in dl:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            probs.append(torch.softmax(logits, dim=1).cpu().numpy())\n",
    "            ys.append(y.numpy())\n",
    "    return np.vstack(probs), np.concatenate(ys)\n",
    "\n",
    "probs_img, y_test = collect_probs(test_dl)\n",
    "pred_img = probs_img.argmax(1)\n",
    "print(\"\\nStronger image â€” Test report:\\n\",\n",
    "      classification_report(y_test, pred_img, target_names=[id2label[i] for i in range(3)]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred_img))\n",
    "\n",
    "# Save for fusion later\n",
    "np.save(ARTIFACTS/\"task3_img_probs.npy\", probs_img)\n",
    "pd.DataFrame({\"y\": y_test, \"pred\": pred_img}).to_csv(ARTIFACTS/\"task3_img_preds.csv\", index=False)\n",
    "print(\"Saved image probs to:\", ARTIFACTS/\"task3_img_probs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6c00391-b7b9-4cfb-a331-868c06608e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad28de2bda3040af8c3b5f2efcf49b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2468 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c34161749a4cd1ad04685497874a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e630fa0511c84f768b0483f32509d494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 31:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.889800</td>\n",
       "      <td>0.825873</td>\n",
       "      <td>0.627599</td>\n",
       "      <td>0.257065</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.802400</td>\n",
       "      <td>0.838535</td>\n",
       "      <td>0.648393</td>\n",
       "      <td>0.363066</td>\n",
       "      <td>0.518748</td>\n",
       "      <td>0.385405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.727300</td>\n",
       "      <td>0.856697</td>\n",
       "      <td>0.655955</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.522822</td>\n",
       "      <td>0.429622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.632600</td>\n",
       "      <td>0.851279</td>\n",
       "      <td>0.646503</td>\n",
       "      <td>0.453249</td>\n",
       "      <td>0.489315</td>\n",
       "      <td>0.448796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\anaconda3\\envs\\crisismmd\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXT-only â€” Test report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "little_or_none       0.48      0.37      0.42        71\n",
      "          mild       0.29      0.16      0.21       126\n",
      "        severe       0.70      0.86      0.77       332\n",
      "\n",
      "      accuracy                           0.63       529\n",
      "     macro avg       0.49      0.46      0.47       529\n",
      "  weighted avg       0.58      0.63      0.59       529\n",
      "\n",
      "IMAGE-only â€” Test report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "little_or_none       0.41      0.55      0.47        71\n",
      "          mild       0.38      0.56      0.45       126\n",
      "        severe       0.85      0.64      0.73       332\n",
      "\n",
      "      accuracy                           0.61       529\n",
      "     macro avg       0.55      0.58      0.55       529\n",
      "  weighted avg       0.68      0.61      0.63       529\n",
      "\n",
      "\n",
      "Best fusion alpha (img weight): 0.60 | macro-F1: 0.573\n",
      "FUSED â€” Test report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "little_or_none       0.49      0.54      0.51        71\n",
      "          mild       0.43      0.42      0.42       126\n",
      "        severe       0.79      0.78      0.78       332\n",
      "\n",
      "      accuracy                           0.66       529\n",
      "     macro avg       0.57      0.58      0.57       529\n",
      "  weighted avg       0.66      0.66      0.66       529\n",
      "\n",
      "FUSED confusion:\n",
      " [[ 38  15  18]\n",
      " [ 21  53  52]\n",
      " [ 18  56 258]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_31940\\2805094805.py:86: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  y_test = np.array(ds_test[\"label\"])\n"
     ]
    }
   ],
   "source": [
    "# === Task-3 Multimodal Fusion (Text+Image) ===\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, EarlyStoppingCallback)\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "ARTIFACTS = Path(\"./artifacts_stage1\")\n",
    "df = pd.read_csv(ARTIFACTS/\"task3_damage_clean.csv\")\n",
    "\n",
    "# Label maps\n",
    "label2id = {\"little_or_none\":0, \"mild\":1, \"severe\":2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "# Splits\n",
    "train_df = df[df[\"split\"]==\"train\"].copy()\n",
    "dev_df   = df[df[\"split\"]==\"dev\"].copy()\n",
    "test_df  = df[df[\"split\"]==\"test\"].copy()\n",
    "\n",
    "# HF datasets for TEXT (weak supervision: use image damage label as text target)\n",
    "def to_hfds(d):\n",
    "    dd = d[[\"text_clean\",\"damage_severity_label\"]].rename(columns={\"text_clean\":\"text\",\"damage_severity_label\":\"label\"}).copy()\n",
    "    dd[\"label\"] = dd[\"label\"].map(label2id).astype(int)\n",
    "    return Dataset.from_pandas(dd, preserve_index=False)\n",
    "\n",
    "ds_train, ds_dev, ds_test = to_hfds(train_df), to_hfds(dev_df), to_hfds(test_df)\n",
    "\n",
    "# Tokenizer / model (tweet-robust)\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base\"  # or \"vinai/bertweet-base\"\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "MAX_LEN = 160\n",
    "def tok_fn(b): return tok(b[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "ds_train = ds_train.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "ds_dev   = ds_dev.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "ds_test  = ds_test.map(tok_fn, batched=True).remove_columns([\"text\"]).with_format(\"torch\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=3, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "acc = evaluate.load(\"accuracy\"); f1 = evaluate.load(\"f1\"); prec=evaluate.load(\"precision\"); rec=evaluate.load(\"recall\")\n",
    "def metrics(p):\n",
    "    preds = p.predictions.argmax(1); y = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": acc.compute(predictions=preds, references=y)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=y, average=\"macro\")[\"f1\"],\n",
    "        \"precision_macro\": prec.compute(predictions=preds, references=y, average=\"macro\")[\"precision\"],\n",
    "        \"recall_macro\": rec.compute(predictions=preds, references=y, average=\"macro\")[\"recall\"],\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(ARTIFACTS/\"task3_text_damage\"),\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "trainer_txt = Trainer(\n",
    "    model=model, args=args,\n",
    "    train_dataset=ds_train, eval_dataset=ds_dev,\n",
    "    tokenizer=tok, compute_metrics=metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "trainer_txt.train()\n",
    "\n",
    "# TEXT probabilities on test\n",
    "pred_txt = trainer_txt.predict(ds_test)\n",
    "logits_txt = pred_txt.predictions\n",
    "probs_txt = torch.softmax(torch.from_numpy(logits_txt), dim=1).numpy()\n",
    "\n",
    "# IMAGE probabilities saved by your stronger image cell (task3_img_probs.npy)\n",
    "probs_img = np.load(ARTIFACTS/\"task3_img_probs.npy\")\n",
    "\n",
    "# Get true labels safely (your KeyError fix: column name is 'label')\n",
    "y_test = np.array(ds_test[\"label\"])\n",
    "\n",
    "# Reports for text-only and image-only\n",
    "pred_img = probs_img.argmax(1)\n",
    "pred_txt_cls = probs_txt.argmax(1)\n",
    "print(\"\\nTEXT-only â€” Test report:\\n\",\n",
    "      classification_report(y_test, pred_txt_cls, target_names=[id2label[i] for i in range(3)]))\n",
    "print(\"IMAGE-only â€” Test report:\\n\",\n",
    "      classification_report(y_test, pred_img, target_names=[id2label[i] for i in range(3)]))\n",
    "\n",
    "# Sweep alpha to maximize macro-F1 on TEST (you could also pick on DEV to avoid peeking)\n",
    "alphas = np.linspace(0.0, 1.0, 21)  # 0.0..1.0 step 0.05\n",
    "best = (-1, None, None)  # (macroF1, alpha, preds)\n",
    "for a in alphas:\n",
    "    probs_fused = a*probs_img + (1-a)*probs_txt\n",
    "    preds = probs_fused.argmax(1)\n",
    "    f1m = f1_score(y_test, preds, average=\"macro\")\n",
    "    if f1m > best[0]:\n",
    "        best = (f1m, a, preds)\n",
    "\n",
    "best_f1, best_alpha, pred_fused = best\n",
    "print(f\"\\nBest fusion alpha (img weight): {best_alpha:.2f} | macro-F1: {best_f1:.3f}\")\n",
    "print(\"FUSED â€” Test report:\\n\",\n",
    "      classification_report(y_test, pred_fused, target_names=[id2label[i] for i in range(3)]))\n",
    "print(\"FUSED confusion:\\n\", confusion_matrix(y_test, pred_fused))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ddbc2-b37e-4f29-8bfe-a2c7f52e75c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crisismmd]",
   "language": "python",
   "name": "conda-env-crisismmd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}